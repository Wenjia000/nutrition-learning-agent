{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgxkrZe9vFUMYO6l38E/zJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wenjia000/nutrition-learning-agent/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw5TIR_wAszc",
        "outputId": "8e4eb6f0-50f6-484b-a25b-105ec72dee2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Your answer:\n",
            "Which has more calcium: cereals rte ralston crispy hexagons or beans snap?\n",
            "(type 'hint' or 'stop')\n",
            "> stop\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q langgraph langchain-openai scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from langgraph.graph import StateGraph\n",
        "from typing import TypedDict, Optional, List\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os\n",
        "from google.colab import drive, userdata\n",
        "\n",
        "# load API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# LLM setup\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.7,\n",
        "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
        ")\n",
        "\n",
        "# load data\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/USDA.csv')\n",
        "\n",
        "\n",
        "# make food name shorter\n",
        "def simplify_name(desc: str) -> str:\n",
        "    parts = desc.split(\",\")\n",
        "    if len(parts) >= 2:\n",
        "        return parts[0].lower().strip() + \" \" + parts[1].lower().strip()\n",
        "    return parts[0].lower().strip()\n",
        "\n",
        "\n",
        "# question generators(easy, meduim, hard)\n",
        "\n",
        "NUTRIENTS_EASY = [\"Protein\", \"Calories\", \"TotalFat\", \"Carbohydrate\", \"Sugar\", \"Calcium\"]\n",
        "\n",
        "GOALS_MEDIUM = {\n",
        "    \"build muscle\": \"Protein\",\n",
        "    \"bone health\": \"Calcium\",\n",
        "    \"a low-fat diet\": \"TotalFat\",\n",
        "    \"a low-sugar diet\": \"Sugar\",\n",
        "    \"heart health\": \"Sodium\",\n",
        "}\n",
        "\n",
        "def generate_easy_question(df):\n",
        "    sampled = df.sample(2)\n",
        "    f1, f2 = sampled.iloc[0], sampled.iloc[1]\n",
        "    name1 = simplify_name(f1[\"Description\"])\n",
        "    name2 = simplify_name(f2[\"Description\"])\n",
        "    nutrient = random.choice(NUTRIENTS_EASY)\n",
        "    question = f\"Which has more {nutrient.lower()}: {name1} or {name2}?\"\n",
        "    answer = name1 if f1[nutrient] > f2[nutrient] else name2\n",
        "    return {\"question\": question, \"answer\": answer, \"difficulty\": \"easy\"}\n",
        "\n",
        "\n",
        "def generate_medium_question(df):\n",
        "    sampled = df.sample(2)\n",
        "    f1, f2 = sampled.iloc[0], sampled.iloc[1]\n",
        "    name1 = simplify_name(f1[\"Description\"])\n",
        "    name2 = simplify_name(f2[\"Description\"])\n",
        "    goal, nutrient = random.choice(list(GOALS_MEDIUM.items()))\n",
        "    v1, v2 = f1[nutrient], f2[nutrient]\n",
        "    question = f\"If you're trying to {goal}, which is better: {name1} or {name2}?\"\n",
        "    if \"low\" in goal:\n",
        "        answer = name1 if v1 < v2 else name2\n",
        "    else:\n",
        "        answer = name1 if v1 > v2 else name2\n",
        "    return {\"question\": question, \"answer\": answer, \"difficulty\": \"medium\"}\n",
        "\n",
        "\n",
        "def generate_hard_question(df):\n",
        "    sampled = df.sample(3)\n",
        "    f1, f2, f3 = sampled.iloc[0], sampled.iloc[1], sampled.iloc[2]\n",
        "    name1 = simplify_name(f1[\"Description\"])\n",
        "    name2 = simplify_name(f2[\"Description\"])\n",
        "    name3 = simplify_name(f3[\"Description\"])\n",
        "    question = f\"You want high protein but low fat. Which is best: {name1}, {name2}, or {name3}?\"\n",
        "    def score(food):\n",
        "        return food[\"Protein\"] - food[\"TotalFat\"]\n",
        "    scores = {name1: score(f1), name2: score(f2), name3: score(f3)}\n",
        "    answer = max(scores, key=scores.get)\n",
        "    return {\"question\": question, \"answer\": answer, \"difficulty\": \"hard\"}\n",
        "\n",
        "\n",
        "# logistic regression classifier\n",
        "np.random.seed(0)\n",
        "\n",
        "data = {\n",
        "    \"accuracy\": np.random.rand(500),\n",
        "    \"easy_correct\": np.random.randint(0, 5, 500),\n",
        "    \"medium_correct\": np.random.randint(0, 5, 500),\n",
        "    \"hard_correct\": np.random.randint(0, 5, 500),\n",
        "}\n",
        "df_sim = pd.DataFrame(data)\n",
        "\n",
        "df_sim[\"level\"] = pd.cut(\n",
        "    df_sim[\"accuracy\"],\n",
        "    bins=[0, 0.4, 0.7, 1.0],\n",
        "    labels=[0, 1, 2]\n",
        ").astype(int)\n",
        "\n",
        "X = df_sim[[\"accuracy\", \"easy_correct\", \"medium_correct\", \"hard_correct\"]]\n",
        "y = df_sim[\"level\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=0\n",
        ")\n",
        "\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# agent state\n",
        "class AgentState(TypedDict):\n",
        "    last_question: Optional[str]\n",
        "    last_answer: Optional[str]\n",
        "    last_difficulty: Optional[str]\n",
        "    user_answer: Optional[str]\n",
        "    history: List[str]\n",
        "    correct_list: List[int]\n",
        "    accuracy: float\n",
        "    easy_correct: int\n",
        "    medium_correct: int\n",
        "    hard_correct: int\n",
        "    predicted_level: Optional[int]\n",
        "    continue_flag: bool\n",
        "    ab_version: str\n",
        "\n",
        "\n",
        "# nodes\n",
        "\n",
        "# randomly assign A/B version\n",
        "def assign_ab_version(state: AgentState):\n",
        "    state[\"ab_version\"] = random.choice([\"A\", \"B\"])\n",
        "    state[\"history\"].append(f\"AB version = {state['ab_version']}\")\n",
        "    return state\n",
        "\n",
        "# greeting node\n",
        "def greeting(state: AgentState):\n",
        "    state[\"history\"].append(\"Hello! Let's start your nutrition learning session.\")\n",
        "    if state[\"predicted_level\"] is None:\n",
        "        state[\"predicted_level\"] = 0\n",
        "    return state\n",
        "\n",
        "# choose difficulty and generate question\n",
        "def ask_question(state: AgentState):\n",
        "    lvl = state[\"predicted_level\"]\n",
        "    if lvl == 0:\n",
        "        qa = generate_easy_question(df)\n",
        "    elif lvl == 1:\n",
        "        qa = generate_medium_question(df)\n",
        "    else:\n",
        "        qa = generate_hard_question(df)\n",
        "    state[\"last_question\"] = qa[\"question\"]\n",
        "    state[\"last_answer\"] = qa[\"answer\"]\n",
        "    state[\"last_difficulty\"] = qa[\"difficulty\"]\n",
        "    state[\"history\"].append(\"QUESTION: \" + qa[\"question\"])\n",
        "    return state\n",
        "\n",
        "# tutor node using A/B difference\n",
        "def llm_node(state: AgentState):\n",
        "    q = state[\"last_question\"]\n",
        "    if state[\"ab_version\"] == \"A\":\n",
        "        prompt = f\"Encourage the student to answer: {q}\"\n",
        "    else:\n",
        "        prompt = f\"Give a step-by-step friendly explanation and encourage answering:\\n{q}\"\n",
        "    reply = llm.invoke(prompt).content\n",
        "    state[\"history\"].append(\"TUTOR: \" + reply)\n",
        "    return state\n",
        "\n",
        "\n",
        "def collect_answer(state: AgentState):\n",
        "    ans = input(\n",
        "        f\"Your answer:\\n{state['last_question']}\\n(type 'hint' or 'stop')\\n> \"\n",
        "    ).strip().lower()\n",
        "    state[\"user_answer\"] = ans\n",
        "    return state\n",
        "\n",
        "# route: hint / grade / end\n",
        "def route_user_action(state: AgentState):\n",
        "    if state[\"user_answer\"] == \"hint\":\n",
        "        return \"hint\"\n",
        "    if state[\"user_answer\"] == \"stop\":\n",
        "        return \"end\"\n",
        "    return \"grade\"\n",
        "\n",
        "# hint node with A/B variation\n",
        "def hint_node(state: AgentState):\n",
        "    q = state[\"last_question\"]\n",
        "    diff = state[\"last_difficulty\"]\n",
        "    if state[\"ab_version\"] == \"A\":\n",
        "        prompt = f\"Give a short hint:\\n{q}\"\n",
        "    else:\n",
        "        prompt = f\"Give a detailed reasoning-style hint for this {diff} question:\\n{q}\"\n",
        "    msg = llm.invoke(prompt).content\n",
        "    state[\"history\"].append(\"HINT: \" + msg)\n",
        "    print(\"\\n[HINT] \" + msg + \"\\n\")\n",
        "    return state\n",
        "\n",
        "# grade answer\n",
        "def grade_answer(state: AgentState):\n",
        "    user = state[\"user_answer\"]\n",
        "    correct = state[\"last_answer\"]\n",
        "    diff = state[\"last_difficulty\"]\n",
        "\n",
        "    if user is None:\n",
        "        return state\n",
        "\n",
        "    is_correct = 1 if user == correct else 0\n",
        "    state[\"correct_list\"].append(is_correct)\n",
        "\n",
        "    if is_correct:\n",
        "        if diff == \"easy\": state[\"easy_correct\"] += 1\n",
        "        if diff == \"medium\": state[\"medium_correct\"] += 1\n",
        "        if diff == \"hard\": state[\"hard_correct\"] += 1\n",
        "\n",
        "    if len(state[\"correct_list\"]) >= 5:\n",
        "        state[\"accuracy\"] = sum(state[\"correct_list\"][-5:]) / 5\n",
        "\n",
        "    print(f\"\\nRESULT: {'correct' if is_correct else 'incorrect'}\\n\")\n",
        "    return state\n",
        "\n",
        "# classifier update\n",
        "def classify_level(state: AgentState):\n",
        "    user_X = pd.DataFrame([{\n",
        "        \"accuracy\": state[\"accuracy\"],\n",
        "        \"easy_correct\": state[\"easy_correct\"],\n",
        "        \"medium_correct\": state[\"medium_correct\"],\n",
        "        \"hard_correct\": state[\"hard_correct\"],\n",
        "    }])\n",
        "    lvl = int(clf.predict(user_X)[0])\n",
        "    state[\"predicted_level\"] = lvl\n",
        "    print(\"LEVEL =\", lvl)\n",
        "    return state\n",
        "\n",
        "# continue rule\n",
        "def continue_or_end(state: AgentState):\n",
        "    if len(state[\"correct_list\"]) >= 10:\n",
        "        state[\"continue_flag\"] = False\n",
        "    return state\n",
        "\n",
        "\n",
        "# build graph\n",
        "# Flow:\n",
        "# assign_ab\n",
        "#   → greeting\n",
        "#       → ask_question\n",
        "#           → llm_talk\n",
        "#               → collect_answer\n",
        "#                   → hint → collect_answer\n",
        "#                   → grade → continue_check → classify → ask_question\n",
        "#                   → end\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"assign_ab\", assign_ab_version)\n",
        "graph.add_node(\"greeting\", greeting)\n",
        "graph.add_node(\"ask_question\", ask_question)\n",
        "graph.add_node(\"llm_talk\", llm_node)\n",
        "graph.add_node(\"collect_answer\", collect_answer)\n",
        "graph.add_node(\"hint\", hint_node)\n",
        "graph.add_node(\"grade\", grade_answer)\n",
        "graph.add_node(\"classify\", classify_level)\n",
        "graph.add_node(\"continue_check\", continue_or_end)\n",
        "\n",
        "graph.set_entry_point(\"assign_ab\")\n",
        "graph.add_edge(\"assign_ab\", \"greeting\")\n",
        "graph.add_edge(\"greeting\", \"ask_question\")\n",
        "graph.add_edge(\"ask_question\", \"llm_talk\")\n",
        "graph.add_edge(\"llm_talk\", \"collect_answer\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"collect_answer\",\n",
        "    route_user_action,\n",
        "    {\n",
        "        \"hint\": \"hint\",\n",
        "        \"grade\": \"grade\",\n",
        "        \"end\": \"__end__\",\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"hint\", \"collect_answer\")\n",
        "graph.add_edge(\"grade\", \"continue_check\")\n",
        "\n",
        "graph.add_conditional_edges(\n",
        "    \"continue_check\",\n",
        "    lambda s: \"continue\" if s[\"continue_flag\"] else \"end\",\n",
        "    {\n",
        "        \"continue\": \"classify\",\n",
        "        \"end\": \"__end__\",\n",
        "    }\n",
        ")\n",
        "\n",
        "graph.add_edge(\"classify\", \"ask_question\")\n",
        "\n",
        "app = graph.compile()\n",
        "\n",
        "initial_state: AgentState = {\n",
        "    \"last_question\": None,\n",
        "    \"last_answer\": None,\n",
        "    \"last_difficulty\": None,\n",
        "    \"user_answer\": None,\n",
        "    \"history\": [],\n",
        "    \"correct_list\": [],\n",
        "    \"accuracy\": 0.0,\n",
        "    \"easy_correct\": 0,\n",
        "    \"medium_correct\": 0,\n",
        "    \"hard_correct\": 0,\n",
        "    \"predicted_level\": None,\n",
        "    \"continue_flag\": True,\n",
        "    \"ab_version\": \"A\",\n",
        "}\n",
        "\n",
        "final_state = app.invoke(initial_state)"
      ]
    }
  ]
}